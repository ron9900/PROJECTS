# -*- coding: utf-8 -*-
"""Model Building.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a29tftKKdOFdPTUC233qQ_5RmJEE_iWN
"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import DenseNet201
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import numpy as np
import os

import zipfile
import os

# Define paths
zip_path = "/content/drive/MyDrive/final.zip"  # Update with your uploaded ZIP filename
extract_path = "/content/dataset"

# Extract the dataset
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("✅ Dataset extracted to:", extract_path)

import os
import shutil
import random

# Define paths
SOURCE_DIR = "/content/dataset/final"  # Path to extracted dataset
DEST_DIR = "/content/split"  # Path where train/test split will be created

TRAIN_SPLIT = 0.8  # 80% train, 20% test

# Function to create directories
def create_dir(path):
    if not os.path.exists(path):
        os.makedirs(path)

# Loop through categories and split images
for stage in ["8_celled", "morula", "blastocyst"]:
    for grade in ["grade_a", "grade_b", "grade_c"]:
        source_path = os.path.join(SOURCE_DIR, stage, grade)

        if not os.path.exists(source_path):
            print(f"⚠️ Warning: Source directory not found: {source_path}")
            continue

        images = os.listdir(source_path)

        # Shuffle images randomly
        random.shuffle(images)

        # Calculate split index
        split_idx = int(len(images) * TRAIN_SPLIT)

        # Define train & test paths
        train_path = os.path.join(DEST_DIR, "train", stage, grade)
        test_path = os.path.join(DEST_DIR, "test", stage, grade)

        # Create directories
        create_dir(train_path)
        create_dir(test_path)

        # Move images to train & test folders
        for i, img in enumerate(images):
            src_img = os.path.join(source_path, img)
            if i < split_idx:
                shutil.copy(src_img, os.path.join(train_path, img))  # Copy instead of move
            else:
                shutil.copy(src_img, os.path.join(test_path, img))

print("✅ Images successfully split into train/test folders!")

# Define directories (UPDATE paths if needed)
TRAIN_DIR = "/content/split/train"
TEST_DIR = "/content/split/test"

# Image properties
IMG_SIZE = (224, 224)
BATCH_SIZE = 32

# Data Augmentation for Training
train_datagen = ImageDataGenerator(
    rescale=1.0 / 255,  # Normalize images
    rotation_range=30,   # Random rotation
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Only rescale for test set (no augmentation)
test_datagen = ImageDataGenerator(rescale=1.0 / 255)

# Load images
train_generator = train_datagen.flow_from_directory(
    TRAIN_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="categorical"
)

test_generator = test_datagen.flow_from_directory(
    TEST_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="categorical"
)

print("✅ Data successfully loaded!")

# Load DenseNet-201 model (without top layers)
base_model = DenseNet201(weights="imagenet", include_top=False, input_shape=(224, 224, 3))

# Freeze base model layers (for transfer learning)
base_model.trainable = False

# Add custom layers on top
x = GlobalAveragePooling2D()(base_model.output)  # Global pooling layer
x = Dense(256, activation="relu")(x)  # Fully connected layer
x = Dropout(0.5)(x)  # Dropout for regularization
output = Dense(train_generator.num_classes, activation="softmax")(x)  # Output layer

# Define final model
model = Model(inputs=base_model.input, outputs=output)

# Compile model
model.compile(optimizer=Adam(learning_rate=0.0001), loss="categorical_crossentropy", metrics=["accuracy"])

print("✅ DenseNet-201 Model is ready!")
model.summary()

# Train the model
model.fit(train_generator, validation_data=test_generator, epochs=10)

# Save the trained model
model.save("densenet_model.h5")
print("✅ Model saved successfully as 'densenet_model.h5'")

# Train model
EPOCHS = 20

history = model.fit(
    train_generator,
    validation_data=test_generator,
    epochs=EPOCHS
)

print("✅ Training completed!")

# Evaluate on test set
test_loss, test_acc = model.evaluate(test_generator)
print(f"✅ Test Accuracy: {test_acc:.2%}")

from tensorflow.keras.preprocessing import image

def predict_image(img_path):
    img = image.load_img(img_path, target_size=IMG_SIZE)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize

    # Predict
    prediction = model.predict(img_array)
    predicted_class = np.argmax(prediction)

    # Class labels
    class_labels = list(test_generator.class_indices.keys())

    # Display
    plt.imshow(img)
    plt.title(f"Predicted: {class_labels[predicted_class]}")
    plt.axis("off")
    plt.show()

    print(f"✅ Predicted Class: {class_labels[predicted_class]}")

# Example test image (Update with actual path)
test_image_path = "/content/split/train/8_celled/grade_b/8C GB (10).png"
predict_image(test_image_path)

